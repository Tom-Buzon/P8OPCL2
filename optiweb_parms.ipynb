{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "075a7e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow experiment: optiweb_params\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1) IMPORTS + CONFIGURATION GPU & MLFLOW\n",
    "# ============================================\n",
    "\n",
    "\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import mlflow.sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# GPU models\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# MLflow experiment configuration\n",
    "EXPERIMENT_NAME = \"optiweb_params\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"MLflow experiment:\", EXPERIMENT_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229caf96",
   "metadata": {},
   "source": [
    " CELLULE 2 — Chargement data complète (OptiWeb 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dcfcdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataset complet OptiWeb…\n",
      "Train shape: (307507, 765)\n",
      "Test  shape: (48744, 765)\n",
      "Features logged: 765\n"
     ]
    }
   ],
   "source": [
    "### CELLULE 2 — Chargement data complète (OptiWeb 100%)\n",
    "\n",
    "from app.features_optiweb import apply_eda\n",
    "\n",
    "print(\"Chargement du dataset complet OptiWeb…\")\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, test_ids = apply_eda()\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test  shape:\", X_test.shape)\n",
    "\n",
    "# Sauvegarde des features\n",
    "features_used = list(X_train.columns)\n",
    "\n",
    "with open(\"features_used.json\", \"w\") as f:\n",
    "    json.dump(features_used, f, indent=2)\n",
    "\n",
    "print(\"Features logged:\", len(features_used))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10defc5b",
   "metadata": {},
   "source": [
    "Cellule 3 — Définition des modèles GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25627c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight = 11.386988922457201\n",
      "Modèles GPU chargés : ['xgboost_gpu', 'lightgbm_gpu', 'catboost_gpu']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3) Cellule 3 — Définition des modèles GPU\n",
    "# ============================================\n",
    "\n",
    "# Calcul automatique du poids\n",
    "n_pos = y_train.sum()\n",
    "n_neg = len(y_train) - n_pos\n",
    "scale_pos = n_neg / n_pos\n",
    "print(\"scale_pos_weight =\", scale_pos)\n",
    "\n",
    "models_gpu = {\n",
    "    \"xgboost_gpu\": XGBClassifier(\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "        n_estimators=400,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=scale_pos,   \n",
    "        random_state=SEED,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"lightgbm_gpu\": lgb.LGBMClassifier(\n",
    "        device_type=\"gpu\",\n",
    "        boosting_type=\"gbdt\",\n",
    "        n_estimators=300,\n",
    "        num_leaves=40,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=scale_pos,   \n",
    "        random_state=SEED\n",
    "    ),\n",
    "\n",
    "    \"catboost_gpu\": CatBoostClassifier(\n",
    "        task_type=\"GPU\",\n",
    "        devices='0',\n",
    "        iterations=500,\n",
    "        depth=8,\n",
    "        learning_rate=0.05,\n",
    "        loss_function=\"Logloss\",\n",
    "        scale_pos_weight=scale_pos,     \n",
    "        verbose=False,\n",
    "        random_state=SEED\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Modèles GPU chargés :\", list(models_gpu.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7df617",
   "metadata": {},
   "source": [
    "Cellule 4 — Cross-validation GPU + MLflow logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc3430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Début CV GPU ===\n",
      "\n",
      "=== CV xgboost_gpu ===\n",
      "xgboost_gpu → mean AUC=0.7812 std=0.0033\n",
      "\n",
      "=== CV lightgbm_gpu ===\n",
      "lightgbm_gpu → mean AUC=0.7860 std=0.0041\n",
      "\n",
      "=== CV catboost_gpu ===\n",
      "catboost_gpu → mean AUC=0.7835 std=0.0035\n",
      "\n",
      "Résultats : [{'name': 'xgboost_gpu', 'auc': 0.7812497664360525}, {'name': 'lightgbm_gpu', 'auc': 0.786015698485207}, {'name': 'catboost_gpu', 'auc': 0.7834986175806}]\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4) Cellule 4 — Cross-validation GPU + MLflow logging\n",
    "# ============================================\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "with mlflow.start_run(run_name=\"comparison_gpu_models\") as parent_run:\n",
    "\n",
    "    # Log des features\n",
    "    mlflow.log_dict({\"features_used\": features_used}, \"features_used.json\")\n",
    "\n",
    "    print(\"=== Début CV GPU ===\")\n",
    "\n",
    "    for name, model in models_gpu.items():\n",
    "        print(f\"\\n=== CV {name} ===\")\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"cv_{name}\", nested=True):\n",
    "\n",
    "            scores = cross_val_score(\n",
    "                model,\n",
    "                X_train,\n",
    "                y_train,\n",
    "                cv=cv,\n",
    "                scoring=\"roc_auc\",\n",
    "                n_jobs=11\n",
    "            )\n",
    "\n",
    "            mean_auc = float(np.mean(scores))\n",
    "            std_auc = float(np.std(scores))\n",
    "\n",
    "            mlflow.log_metric(\"roc_auc_mean\", mean_auc)\n",
    "            mlflow.log_metric(\"roc_auc_std\", std_auc)\n",
    "\n",
    "            print(f\"{name} → mean AUC={mean_auc:.4f} std={std_auc:.4f}\")\n",
    "\n",
    "            results.append({\n",
    "                \"name\": name,\n",
    "                \"auc\": mean_auc\n",
    "            })\n",
    "\n",
    "print(\"\\nRésultats :\", results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0bbbe",
   "metadata": {},
   "source": [
    "Cellule 5 — Baseline AUC full features (référence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1f950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL: lightgbm_gpu AUC: 0.786015698485207\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 5) Cellule 5 — Sélection du meilleur modèle\n",
    "# ============================================\n",
    "\n",
    "best = max(results, key=lambda r: r[\"auc\"])\n",
    "best_family = best[\"name\"]\n",
    "\n",
    "print(\"BEST MODEL:\", best_family, \"AUC:\", best[\"auc\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fa63d0",
   "metadata": {},
   "source": [
    "Cellule 6 — OPTUNA (30 min max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd7adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 14:12:50,930] A new study created in memory with name: no-name-3f242d13-9771-4501-ab6f-21862fd7894a\n",
      "[I 2025-11-13 14:13:48,800] Trial 0 finished with value: 0.7805691793141006 and parameters: {'n_estimators': 547, 'num_leaves': 20, 'learning_rate': 0.11584583329083413, 'subsample': 0.6402478279673515, 'colsample_bytree': 0.867329489950565}. Best is trial 0 with value: 0.7805691793141006.\n",
      "[I 2025-11-13 14:17:18,728] Trial 1 finished with value: 0.7699641491917149 and parameters: {'n_estimators': 511, 'num_leaves': 148, 'learning_rate': 0.06243369160916571, 'subsample': 0.9290548986040734, 'colsample_bytree': 0.8792398879521577}. Best is trial 0 with value: 0.7805691793141006.\n",
      "[I 2025-11-13 14:23:05,859] Trial 2 finished with value: 0.7720678388918845 and parameters: {'n_estimators': 746, 'num_leaves': 179, 'learning_rate': 0.04116626075537672, 'subsample': 0.6629506631020313, 'colsample_bytree': 0.835662235142895}. Best is trial 0 with value: 0.7805691793141006.\n",
      "[I 2025-11-13 14:26:09,591] Trial 3 finished with value: 0.7325079744517963 and parameters: {'n_estimators': 791, 'num_leaves': 82, 'learning_rate': 0.18875093033172138, 'subsample': 0.6171393607339289, 'colsample_bytree': 0.836158229297383}. Best is trial 0 with value: 0.7805691793141006.\n",
      "[I 2025-11-13 14:30:16,054] Trial 4 finished with value: 0.7363843186000975 and parameters: {'n_estimators': 809, 'num_leaves': 120, 'learning_rate': 0.19044729346953762, 'subsample': 0.6840599022546218, 'colsample_bytree': 0.6768041347991759}. Best is trial 0 with value: 0.7805691793141006.\n",
      "[I 2025-11-13 14:35:39,247] Trial 5 finished with value: 0.7446116580756228 and parameters: {'n_estimators': 731, 'num_leaves': 175, 'learning_rate': 0.18236021925988768, 'subsample': 0.8250887806504281, 'colsample_bytree': 0.84556688724996}. Best is trial 0 with value: 0.7805691793141006.\n",
      "[I 2025-11-13 14:37:27,506] Trial 6 finished with value: 0.7871849078362636 and parameters: {'n_estimators': 875, 'num_leaves': 23, 'learning_rate': 0.02533714281950245, 'subsample': 0.8798790451127203, 'colsample_bytree': 0.9082740591241196}. Best is trial 6 with value: 0.7871849078362636.\n",
      "[I 2025-11-13 14:42:18,566] Trial 7 finished with value: 0.7821345278029289 and parameters: {'n_estimators': 800, 'num_leaves': 132, 'learning_rate': 0.02696629854320231, 'subsample': 0.6032781943424205, 'colsample_bytree': 0.8280611179586551}. Best is trial 6 with value: 0.7871849078362636.\n",
      "[I 2025-11-13 14:46:07,792] Trial 8 finished with value: 0.739742864656076 and parameters: {'n_estimators': 885, 'num_leaves': 94, 'learning_rate': 0.15746598027348896, 'subsample': 0.6531992027047652, 'colsample_bytree': 0.9858703702144945}. Best is trial 6 with value: 0.7871849078362636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'n_estimators': 875, 'num_leaves': 23, 'learning_rate': 0.02533714281950245, 'subsample': 0.8798790451127203, 'colsample_bytree': 0.9082740591241196}\n"
     ]
    }
   ],
   "source": [
    "### CELLULE 6 — OPTUNA : Optimisation du meilleur modèle (30min max)  \n",
    "# ==> peut absorber tout le monde mais normalement cest lgbm :)\n",
    "\n",
    "def build_model(family, params):\n",
    "    \"\"\"Construit un modèle GPU selon la famille gagnante.\"\"\"\n",
    "    if family == \"xgboost_gpu\":\n",
    "        return XGBClassifier(\n",
    "            tree_method=\"hist\",\n",
    "            device=\"cuda\",\n",
    "            eval_metric=\"auc\",\n",
    "            scale_pos_weight=scale_pos,\n",
    "            random_state=SEED,\n",
    "            n_jobs=1,\n",
    "            **params\n",
    "        )\n",
    "    elif family == \"lightgbm_gpu\":\n",
    "        return lgb.LGBMClassifier(\n",
    "            device_type=\"gpu\",\n",
    "            scale_pos_weight=scale_pos,\n",
    "            verbosity=-1,\n",
    "            random_state=SEED,\n",
    "            **params\n",
    "        )\n",
    "    else:  # catboost\n",
    "        return CatBoostClassifier(\n",
    "            task_type=\"GPU\",\n",
    "            devices=\"0\",\n",
    "            scale_pos_weight=scale_pos,\n",
    "            random_state=SEED,\n",
    "            verbose=False,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "\n",
    "def suggest_params(trial, family):\n",
    "    \"\"\"Hyperparameter search space selon modèle.\"\"\"\n",
    "    if family == \"xgboost_gpu\":\n",
    "        return {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1000),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        }\n",
    "\n",
    "    if family == \"lightgbm_gpu\":\n",
    "        return {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1000),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 200),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        }\n",
    "\n",
    "    return {  # catboost\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 300, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3)\n",
    "    }\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = suggest_params(trial, best_family)\n",
    "    model = build_model(best_family, params)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        model, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, timeout=1800)   # <=== 30 minutes max\n",
    "\n",
    "best_params = study.best_params\n",
    "best_auc_optuna = study.best_value\n",
    "print(\"BEST AUC (Optuna CV):\", best_auc_optuna)\n",
    "print(\"BEST PARAMS:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1cb6b3",
   "metadata": {},
   "source": [
    "javais lancé avec job=-1 (pas optimal pour cpu : voici le result pour pouvoir comparer avec le bon :) \n",
    "edit = en fait vu que ma carte a tenu (difficilement) -1 était plus rapide : il fait tout d'un coup, mais il cré du cache qui fume mon disk ... \n",
    "\n",
    "Par soucis de temps je vais consservé la valeur avec job=1 mais si je run optuna sans timeout, il faudrait faire un -1 ( et laisser le pc vivre ça vie aha)\n",
    "\n",
    "[I 2025-11-13 13:31:32,689] A new study created in memory with name: no-name-459a1743-7b94-4f66-8091-12af1b015fd5\n",
    "[I 2025-11-13 13:34:18,256] Trial 0 finished with value: 0.7509510403387881 and parameters: {'n_estimators': 691, 'num_leaves': 131, 'learning_rate': 0.10326228130759496, 'subsample': 0.7042807499704653, 'colsample_bytree': 0.7068775132139175}. Best is trial 0 with value: 0.7509510403387881.\n",
    "[I 2025-11-13 13:36:01,012] Trial 1 finished with value: 0.7758625111784033 and parameters: {'n_estimators': 459, 'num_leaves': 108, 'learning_rate': 0.06286525284068775, 'subsample': 0.6852783165671008, 'colsample_bytree': 0.6904180360324381}. Best is trial 1 with value: 0.7758625111784033.\n",
    "[I 2025-11-13 13:37:07,227] Trial 2 finished with value: 0.7748524488031616 and parameters: {'n_estimators': 484, 'num_leaves': 49, 'learning_rate': 0.09883850630579995, 'subsample': 0.891699274515704, 'colsample_bytree': 0.7647692528508342}. Best is trial 1 with value: 0.7758625111784033.\n",
    "[I 2025-11-13 13:39:13,451] Trial 3 finished with value: 0.7847320777833844 and parameters: {'n_estimators': 376, 'num_leaves': 140, 'learning_rate': 0.03552715539936053, 'subsample': 0.6891832979237428, 'colsample_bytree': 0.7065525510765979}. Best is trial 3 with value: 0.7847320777833844.\n",
    "[I 2025-11-13 13:41:03,892] Trial 4 finished with value: 0.73285447582984 and parameters: {'n_estimators': 814, 'num_leaves': 69, 'learning_rate': 0.19521903806869692, 'subsample': 0.6853986622953963, 'colsample_bytree': 0.8015465331552765}. Best is trial 3 with value: 0.7847320777833844.\n",
    "[I 2025-11-13 13:45:04,979] Trial 5 finished with value: 0.7496802637001826 and parameters: {'n_estimators': 734, 'num_leaves': 192, 'learning_rate': 0.12304428289479118, 'subsample': 0.8556453377352304, 'colsample_bytree': 0.9669232273493538}. Best is trial 3 with value: 0.7847320777833844.\n",
    "[I 2025-11-13 13:47:39,097] Trial 6 finished with value: 0.7523722318055741 and parameters: {'n_estimators': 616, 'num_leaves': 151, 'learning_rate': 0.10191033484332025, 'subsample': 0.9442774167574826, 'colsample_bytree': 0.7588455432033429}. Best is trial 3 with value: 0.7847320777833844.\n",
    "[I 2025-11-13 13:49:53,093] Trial 7 finished with value: 0.7498672455114246 and parameters: {'n_estimators': 867, 'num_leaves': 82, 'learning_rate': 0.10943230452379701, 'subsample': 0.9388844293126615, 'colsample_bytree': 0.749876167155267}. Best is trial 3 with value: 0.7847320777833844.\n",
    "[I 2025-11-13 13:52:15,692] Trial 8 finished with value: 0.7730559514345131 and parameters: {'n_estimators': 830, 'num_leaves': 77, 'learning_rate': 0.057595722009926326, 'subsample': 0.7565971542243666, 'colsample_bytree': 0.8195053671816284}. Best is trial 3 with value: 0.7847320777833844.\n",
    "[I 2025-11-13 13:53:41,491] Trial 9 finished with value: 0.746271025903615 and parameters: {'n_estimators': 315, 'num_leaves': 149, 'learning_rate': 0.15470785920400332, 'subsample': 0.9278315306035411, 'colsample_bytree': 0.8059105563490823}. Best is trial 3 with value: 0.7847320777833844.\n",
    "[I 2025-11-13 13:59:16,749] Trial 10 finished with value: 0.7792609445167787 and parameters: {'n_estimators': 996, 'num_leaves': 197, 'learning_rate': 0.023116679185742305, 'subsample': 0.6016680503322742, 'colsample_bytree': 0.6129559216273155}. Best is trial 3 with value: 0.7847320777833844.\n",
    "[I 2025-11-13 14:05:09,378] Trial 11 finished with value: 0.7853946908952195 and parameters: {'n_estimators': 992, 'num_leaves': 198, 'learning_rate': 0.014666006284901015, 'subsample': 0.6099907428072658, 'colsample_bytree': 0.6322315875944823}. Best is trial 11 with value: 0.7853946908952195.\n",
    "BEST PARAMS: {'n_estimators': 992, 'num_leaves': 198, 'learning_rate': 0.014666006284901015, 'subsample': 0.6099907428072658, 'colsample_bytree': 0.6322315875944823}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aef8b8",
   "metadata": {},
   "source": [
    "Cellule 7 — Entrainement final + MLflow Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ca78a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline AUC (final model) = 0.7872 ± 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle final publié : optiweb_params version 2\n",
      "AUC baseline stockée dans MLflow : roc_auc_mean_final_cv\n"
     ]
    }
   ],
   "source": [
    "### CELLULE 7 — Final training + MLflow Registry (avec AUC baseline)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "BEST_MODEL_NAME = \"optiweb_params\"\n",
    "\n",
    "# 1) Réentraînement final sur tout le train\n",
    "final_model = build_model(best_family, best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# 2) Feature importance → valable pour xgb/lgb/cat\n",
    "try:\n",
    "    importance = final_model.feature_importances_\n",
    "    fi = pd.DataFrame({\"feature\": features_used, \"importance\": importance})\n",
    "    fi.to_csv(\"feature_importance.csv\", index=False)\n",
    "except Exception as e:\n",
    "    print(\"Impossible de calculer les feature_importances_ :\", e)\n",
    "    fi = None\n",
    "\n",
    "# 3) AUC baseline du modèle final (full features)\n",
    "scores_final = cross_val_score(\n",
    "    final_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,                  # même StratifiedKFold que plus haut\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=1\n",
    ")\n",
    "baseline_auc = float(scores_final.mean())\n",
    "baseline_std = float(scores_final.std())\n",
    "print(f\"Baseline AUC (final model) = {baseline_auc:.4f} ± {baseline_std:.4f}\")\n",
    "\n",
    "# 4) Save params YAML\n",
    "with open(\"best_params.yaml\", \"w\") as f:\n",
    "    yaml.dump(best_params, f)\n",
    "\n",
    "# 5) ----- MLflow Logging -----\n",
    "with mlflow.start_run(run_name=\"final_optiweb_model\") as run:\n",
    "\n",
    "    # features + hyperparams (en artefacts)\n",
    "    mlflow.log_dict({\"features_used\": features_used}, \"features_used.json\")\n",
    "    mlflow.log_artifact(\"best_params.yaml\")\n",
    "    if fi is not None:\n",
    "        mlflow.log_artifact(\"feature_importance.csv\")\n",
    "\n",
    "    # métriques de perf du modèle final (baseline pour ton futur top-K)\n",
    "    mlflow.log_metric(\"roc_auc_mean_final_cv\", baseline_auc)\n",
    "    mlflow.log_metric(\"roc_auc_std_final_cv\", baseline_std)\n",
    "    mlflow.log_param(\"best_family\", best_family)  # pratique pour filtrer\n",
    "\n",
    "    # Log du modèle dans l’artefact store\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=final_model,\n",
    "        name=\"optiweb_params\",\n",
    "        input_example=X_train.iloc[:5],\n",
    "    )\n",
    "\n",
    "# 6) Model Registry\n",
    "client = MlflowClient()\n",
    "\n",
    "try:\n",
    "    client.create_registered_model(BEST_MODEL_NAME)\n",
    "except Exception:\n",
    "    # déjà créé, on ignore\n",
    "    pass\n",
    "\n",
    "mv = client.create_model_version(\n",
    "    name=BEST_MODEL_NAME,\n",
    "    source=model_info.model_uri.replace(\"runs:/\", \"mlflow-artifacts:/\"),\n",
    "    run_id=run.info.run_id\n",
    ")\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=BEST_MODEL_NAME,\n",
    "    version=mv.version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "\n",
    "print(\"Modèle final publié :\", BEST_MODEL_NAME, \"version\", mv.version)\n",
    "print(\"AUC baseline stockée dans MLflow : roc_auc_mean_final_cv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6-py3.10 (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
